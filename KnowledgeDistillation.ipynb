{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3796,
     "status": "ok",
     "timestamp": 1744843132277,
     "user": {
      "displayName": "hardik makkar",
      "userId": "11652027753526196874"
     },
     "user_tz": -330
    },
    "id": "bHPX8BMnvE3w"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168,
     "referenced_widgets": [
      "78db99cb538f4c1fb8c4e8157384f2e7",
      "e4f907a8b73445e6892efa5edbfaa404",
      "c7e427b6d700455bbba5afdd91f82dbe",
      "514d83e83af1484fb0516508622bf9fc",
      "38316b190fb24676a3218fab0657cb40",
      "1d2b4ff97272434a8bcc4252a8a20e31",
      "9ef3626186be41008512c13189484006",
      "9023526d9cbd4c7d914590b5d3989225",
      "c8e68aaa37e8433d9919183fc89aa7c6",
      "9411fe9039064a3ba1f718d7ef2e7957",
      "a6315401c7a647aaad39ce7d5a505bc0",
      "0219a41fd49b4a96a4b26e5782875f9e",
      "200f37ca38fb4d1c822a63c650405981",
      "31e44153ed614150ab1d32513a22f748",
      "ef77d6003ede465aa63a3fe3ba020457",
      "1c6188f6a9ab40bc9769877d0df7c50c",
      "a675844974964ca29bd8a7548ada20ac",
      "b08f147583fb46cf854914a3a1f71f28",
      "ed291e900d0c4dc8ae3c13c581672482",
      "3e01eded8252445f973482253eef8296",
      "ae7e909a6f9a4b0d837ca92762bf9aab",
      "131758a7a4024ec5bb25b63af3a73b84",
      "50bbde7352fa4dd3ab54a753ca7b5fe0",
      "b8332619c108410a8bb0f78abeab2743",
      "083683b22ab54e26ae080247e45875b0",
      "b24c35b2e58b4899939ff4a47275c358",
      "cfbee46f02964422be0b01937aa73711",
      "bbdb28ad4087432cb7ed6b5ac28a3637",
      "07a0868e3ab34e9a88d5f72f31b012b9",
      "64e14307bab94f94ad16f2f361906e73",
      "2e9c5ec22f564a6baaaf854eae550929",
      "6ca6875291d34ff7b71253510cf99323",
      "86511ac5521e4445aebd02856d80ff62",
      "eeca760eda424dffa565011274a8a943",
      "b6e09a832bc44c90b5caf58354dd577a",
      "b6201232a9c14eafac6eb36e3dfca02e",
      "fde7db3e942d4df69ea667986d3bfad8",
      "8c3c14e952df4897a4e35e1c78a4dd95",
      "93801890d74e41de832bae4b3fbc09e8",
      "2c8498fa667842098aabe83e0f1bf808",
      "15917060ae364a6fbee77d0c45d60cf6",
      "c44a22b5ac7b4f20887e46fc2bde6c45",
      "759b9298057d483b905004ce0a8e3463",
      "51493544ea1b40edbc5093152f7e4b90",
      "a29ee4ea38424004b29f393664453194",
      "bcb43a8511304f82a21dd788a5f54c10",
      "e9b02128c0de43ec882a40913e30fc45",
      "6ad7e17f2a7e4f5083c6e06bd898da15",
      "bc2a23c4f37d41fa8b0460a5dc26c8c5",
      "3ba12fec0e7b4ca581e02c1210458c6e",
      "7499e83e9df54235943e2e259c2dfdf7",
      "a8e23eba073546b2ab78eefd29fc7677",
      "a202edee1301482d8c29b08389a9b079",
      "58c7344ff3c04e21b3778cac5308aada",
      "25db98fe48924671847caf2b6d42405c",
      "792043125df54d12b2c6f31bc5601d11",
      "e168d0b2c15a459b9c9ddf4dfc70907c",
      "c77fdec2c32748448e4b564224d8c216",
      "6601ba8f0aef421aad905d8981a80daf",
      "be89b2eaa3dc436cbc1308acf25ca809",
      "1262d09763304b83bb77f4a74b009272",
      "17399f44028a4c8e9facbfccd5aa84c3",
      "a2716ccab7ad4d168134241d7ff6b69a",
      "9b18c8c3b494485bbeefd2c313d70d78",
      "93615907fc144cda8166d2d948d2c92c",
      "c775c5638e824eda9a9f10920ee28976"
     ]
    },
    "executionInfo": {
     "elapsed": 104310,
     "status": "ok",
     "timestamp": 1744843237555,
     "user": {
      "displayName": "hardik makkar",
      "userId": "11652027753526196874"
     },
     "user_tz": -330
    },
    "id": "UQm_B-FKvIvZ",
    "outputId": "553e23e9-5453-4410-d8f0-67b34984ff0d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Variant folder /root/tensorflow_datasets/eurosat/rgb/2.0.0 has no dataset_info.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/eurosat/rgb/2.0.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78db99cb538f4c1fb8c4e8157384f2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0219a41fd49b4a96a4b26e5782875f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50bbde7352fa4dd3ab54a753ca7b5fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeca760eda424dffa565011274a8a943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29ee4ea38424004b29f393664453194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792043125df54d12b2c6f31bc5601d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /root/tensorflow_datasets/eurosat/rgb/incomplete.FDP0T8_2.0.0/eurosat-train.tfrecord*...:   0%|     â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset eurosat downloaded and prepared to /root/tensorflow_datasets/eurosat/rgb/2.0.0. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "ds_train, ds_info = tfds.load(\"eurosat/rgb\", split=\"train[:80%]\", as_supervised=True, with_info=True)\n",
    "ds_val = tfds.load(\"eurosat/rgb\", split=\"train[80%:]\", as_supervised=True)\n",
    "\n",
    "ds_train = ds_train.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "num_classes = ds_info.features['label'].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 930399,
     "status": "ok",
     "timestamp": 1744844170203,
     "user": {
      "displayName": "hardik makkar",
      "userId": "11652027753526196874"
     },
     "user_tz": -330
    },
    "id": "COvn6HsfvM7q",
    "outputId": "69ca3246-963b-4df3-ba39-da7b4f315cda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
      "\n",
      "ðŸ”§ Training Teacher Model...\n",
      "Epoch 1/5\n",
      "\u001b[1m675/675\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 228ms/step - accuracy: 0.5342 - loss: 1.3930 - val_accuracy: 0.7524 - val_loss: 0.7126\n",
      "Epoch 2/5\n",
      "\u001b[1m675/675\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 235ms/step - accuracy: 0.7104 - loss: 0.7979 - val_accuracy: 0.8170 - val_loss: 0.5452\n",
      "Epoch 3/5\n",
      "\u001b[1m675/675\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 235ms/step - accuracy: 0.7702 - loss: 0.6522 - val_accuracy: 0.8331 - val_loss: 0.4888\n",
      "Epoch 4/5\n",
      "\u001b[1m675/675\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 217ms/step - accuracy: 0.7825 - loss: 0.6004 - val_accuracy: 0.8363 - val_loss: 0.4608\n",
      "Epoch 5/5\n",
      "\u001b[1m675/675\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 235ms/step - accuracy: 0.8017 - loss: 0.5607 - val_accuracy: 0.8369 - val_loss: 0.4750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7af3f23b8e50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = tf.keras.applications.VGG16(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
    "base_model.trainable = False  # Freeze convolutional base\n",
    "\n",
    "teacher_model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),  # updated hidden layer\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(num_classes)  # logits (no softmax)\n",
    "])\n",
    "\n",
    "teacher_model.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "print(\"\\nðŸ”§ Training Teacher Model...\")\n",
    "teacher_model.fit(ds_train, validation_data=ds_val, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1744844170338,
     "user": {
      "displayName": "hardik makkar",
      "userId": "11652027753526196874"
     },
     "user_tz": -330
    },
    "id": "c-PC9YetvVMH",
    "outputId": "9edaf6fb-9829-4a2d-b5d1-6d442c81baa4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def get_student_model():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(224, 224, 3)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "        tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "        tf.keras.layers.Conv2D(256, 3, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "\n",
    "        tf.keras.layers.Dense(256, activation='relu'),  # match with teacher\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(num_classes)  # logits (no softmax)\n",
    "    ])\n",
    "\n",
    "student_model = get_student_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1596398,
     "status": "ok",
     "timestamp": 1744847066836,
     "user": {
      "displayName": "hardik makkar",
      "userId": "11652027753526196874"
     },
     "user_tz": -330
    },
    "id": "ppF0YphT0MFr",
    "outputId": "a05186a3-2fd8-4aa5-9779-651818372190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ“ Training Student with Knowledge Distillation (MSE)...\n",
      "\n",
      "Epoch 1/5\n",
      "Step 0: Total Loss = 1.1083, L1 (MSC) = 0.0686, L2 (CE) = 2.0795\n",
      "Step 50: Total Loss = 1.0549, L1 (MSC) = 0.0585, L2 (CE) = 1.9929\n",
      "Step 100: Total Loss = 0.5119, L1 (MSC) = 0.0318, L2 (CE) = 0.9602\n",
      "Step 150: Total Loss = 0.5897, L1 (MSC) = 0.0321, L2 (CE) = 1.1152\n",
      "Step 200: Total Loss = 0.4071, L1 (MSC) = 0.0270, L2 (CE) = 0.7601\n",
      "Step 250: Total Loss = 0.6219, L1 (MSC) = 0.0330, L2 (CE) = 1.1778\n",
      "Step 300: Total Loss = 0.5237, L1 (MSC) = 0.0385, L2 (CE) = 0.9703\n",
      "Step 350: Total Loss = 0.5651, L1 (MSC) = 0.0329, L2 (CE) = 1.0644\n",
      "Step 400: Total Loss = 0.5232, L1 (MSC) = 0.0326, L2 (CE) = 0.9812\n",
      "Step 450: Total Loss = 0.6926, L1 (MSC) = 0.0418, L2 (CE) = 1.3015\n",
      "Step 500: Total Loss = 0.3021, L1 (MSC) = 0.0267, L2 (CE) = 0.5508\n",
      "Step 550: Total Loss = 0.5280, L1 (MSC) = 0.0347, L2 (CE) = 0.9866\n",
      "Step 600: Total Loss = 0.3569, L1 (MSC) = 0.0201, L2 (CE) = 0.6736\n",
      "Step 650: Total Loss = 0.2529, L1 (MSC) = 0.0210, L2 (CE) = 0.4638\n",
      "\n",
      "Epoch 2/5\n",
      "Step 0: Total Loss = 0.2768, L1 (MSC) = 0.0181, L2 (CE) = 0.5175\n",
      "Step 50: Total Loss = 0.5429, L1 (MSC) = 0.0333, L2 (CE) = 1.0193\n",
      "Step 100: Total Loss = 0.3405, L1 (MSC) = 0.0267, L2 (CE) = 0.6276\n",
      "Step 150: Total Loss = 0.4104, L1 (MSC) = 0.0246, L2 (CE) = 0.7717\n",
      "Step 200: Total Loss = 0.3981, L1 (MSC) = 0.0257, L2 (CE) = 0.7447\n",
      "Step 250: Total Loss = 0.4320, L1 (MSC) = 0.0244, L2 (CE) = 0.8153\n",
      "Step 300: Total Loss = 0.3778, L1 (MSC) = 0.0317, L2 (CE) = 0.6924\n",
      "Step 350: Total Loss = 0.4623, L1 (MSC) = 0.0243, L2 (CE) = 0.8761\n",
      "Step 400: Total Loss = 0.3974, L1 (MSC) = 0.0254, L2 (CE) = 0.7441\n",
      "Step 450: Total Loss = 0.5487, L1 (MSC) = 0.0325, L2 (CE) = 1.0323\n",
      "Step 500: Total Loss = 0.1889, L1 (MSC) = 0.0160, L2 (CE) = 0.3459\n",
      "Step 550: Total Loss = 0.3847, L1 (MSC) = 0.0264, L2 (CE) = 0.7165\n",
      "Step 600: Total Loss = 0.2696, L1 (MSC) = 0.0169, L2 (CE) = 0.5056\n",
      "Step 650: Total Loss = 0.1531, L1 (MSC) = 0.0138, L2 (CE) = 0.2787\n",
      "\n",
      "Epoch 3/5\n",
      "Step 0: Total Loss = 0.2029, L1 (MSC) = 0.0130, L2 (CE) = 0.3797\n",
      "Step 50: Total Loss = 0.4268, L1 (MSC) = 0.0309, L2 (CE) = 0.7918\n",
      "Step 100: Total Loss = 0.1851, L1 (MSC) = 0.0191, L2 (CE) = 0.3321\n",
      "Step 150: Total Loss = 0.3702, L1 (MSC) = 0.0280, L2 (CE) = 0.6844\n",
      "Step 200: Total Loss = 0.3142, L1 (MSC) = 0.0206, L2 (CE) = 0.5872\n",
      "Step 250: Total Loss = 0.3644, L1 (MSC) = 0.0212, L2 (CE) = 0.6865\n",
      "Step 300: Total Loss = 0.2412, L1 (MSC) = 0.0246, L2 (CE) = 0.4332\n",
      "Step 350: Total Loss = 0.3174, L1 (MSC) = 0.0192, L2 (CE) = 0.5964\n",
      "Step 400: Total Loss = 0.2779, L1 (MSC) = 0.0168, L2 (CE) = 0.5224\n",
      "Step 450: Total Loss = 0.3503, L1 (MSC) = 0.0274, L2 (CE) = 0.6458\n",
      "Step 500: Total Loss = 0.1521, L1 (MSC) = 0.0169, L2 (CE) = 0.2702\n",
      "Step 550: Total Loss = 0.2298, L1 (MSC) = 0.0172, L2 (CE) = 0.4253\n",
      "Step 600: Total Loss = 0.2188, L1 (MSC) = 0.0151, L2 (CE) = 0.4074\n",
      "Step 650: Total Loss = 0.1022, L1 (MSC) = 0.0176, L2 (CE) = 0.1693\n",
      "\n",
      "Epoch 4/5\n",
      "Step 0: Total Loss = 0.2093, L1 (MSC) = 0.0163, L2 (CE) = 0.3861\n",
      "Step 50: Total Loss = 0.4224, L1 (MSC) = 0.0341, L2 (CE) = 0.7766\n",
      "Step 100: Total Loss = 0.1406, L1 (MSC) = 0.0138, L2 (CE) = 0.2536\n",
      "Step 150: Total Loss = 0.4019, L1 (MSC) = 0.0278, L2 (CE) = 0.7484\n",
      "Step 200: Total Loss = 0.1995, L1 (MSC) = 0.0150, L2 (CE) = 0.3690\n",
      "Step 250: Total Loss = 0.3147, L1 (MSC) = 0.0181, L2 (CE) = 0.5933\n",
      "Step 300: Total Loss = 0.1508, L1 (MSC) = 0.0190, L2 (CE) = 0.2635\n",
      "Step 350: Total Loss = 0.3308, L1 (MSC) = 0.0211, L2 (CE) = 0.6195\n",
      "Step 400: Total Loss = 0.3226, L1 (MSC) = 0.0197, L2 (CE) = 0.6058\n",
      "Step 450: Total Loss = 0.2842, L1 (MSC) = 0.0238, L2 (CE) = 0.5208\n",
      "Step 500: Total Loss = 0.0955, L1 (MSC) = 0.0154, L2 (CE) = 0.1603\n",
      "Step 550: Total Loss = 0.1950, L1 (MSC) = 0.0193, L2 (CE) = 0.3514\n",
      "Step 600: Total Loss = 0.1541, L1 (MSC) = 0.0127, L2 (CE) = 0.2828\n",
      "Step 650: Total Loss = 0.0930, L1 (MSC) = 0.0148, L2 (CE) = 0.1564\n",
      "\n",
      "Epoch 5/5\n",
      "Step 0: Total Loss = 0.1405, L1 (MSC) = 0.0156, L2 (CE) = 0.2497\n",
      "Step 50: Total Loss = 0.3874, L1 (MSC) = 0.0319, L2 (CE) = 0.7109\n",
      "Step 100: Total Loss = 0.1340, L1 (MSC) = 0.0129, L2 (CE) = 0.2421\n",
      "Step 150: Total Loss = 0.3617, L1 (MSC) = 0.0299, L2 (CE) = 0.6636\n",
      "Step 200: Total Loss = 0.1525, L1 (MSC) = 0.0131, L2 (CE) = 0.2787\n",
      "Step 250: Total Loss = 0.2607, L1 (MSC) = 0.0187, L2 (CE) = 0.4841\n",
      "Step 300: Total Loss = 0.1483, L1 (MSC) = 0.0191, L2 (CE) = 0.2583\n",
      "Step 350: Total Loss = 0.2342, L1 (MSC) = 0.0176, L2 (CE) = 0.4332\n",
      "Step 400: Total Loss = 0.3458, L1 (MSC) = 0.0221, L2 (CE) = 0.6474\n",
      "Step 450: Total Loss = 0.2737, L1 (MSC) = 0.0212, L2 (CE) = 0.5049\n",
      "Step 500: Total Loss = 0.1259, L1 (MSC) = 0.0178, L2 (CE) = 0.2161\n",
      "Step 550: Total Loss = 0.1590, L1 (MSC) = 0.0150, L2 (CE) = 0.2879\n",
      "Step 600: Total Loss = 0.1613, L1 (MSC) = 0.0130, L2 (CE) = 0.2967\n",
      "Step 650: Total Loss = 0.0870, L1 (MSC) = 0.0186, L2 (CE) = 0.1368\n"
     ]
    }
   ],
   "source": [
    "loss_fn_ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "loss_fn_msc = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "epochs = 5\n",
    "alpha = 0.5  # Student CE loss weight\n",
    "beta = 1.0   # Teacher guidance loss weight (MSE)\n",
    "\n",
    "print(\"\\nðŸŽ“ Training Student with Knowledge Distillation (MSE)...\")\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    for step, (x_batch, y_batch) in enumerate(ds_train):\n",
    "        with tf.GradientTape() as tape:\n",
    "            student_logits = student_model(x_batch, training=True)\n",
    "            teacher_logits = teacher_model(x_batch, training=False)\n",
    "\n",
    "            # Cross entropy loss (student vs ground truth)\n",
    "            loss_l2 = loss_fn_ce(y_batch, student_logits)\n",
    "\n",
    "            # MSE loss between teacher and student soft predictions\n",
    "            student_probs = tf.nn.softmax(student_logits)\n",
    "            teacher_probs = tf.nn.softmax(teacher_logits)\n",
    "            loss_l1 = loss_fn_msc(teacher_probs, student_probs)\n",
    "\n",
    "            # Total loss (no alignment)\n",
    "            total_loss = alpha * loss_l2 + beta * loss_l1\n",
    "\n",
    "        grads = tape.gradient(total_loss, student_model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, student_model.trainable_weights))\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            print(f\"Step {step}: Total Loss = {total_loss:.4f}, \"\n",
    "                  f\"L1 (MSC) = {loss_l1:.4f}, L2 (CE) = {loss_l2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10196,
     "status": "ok",
     "timestamp": 1744847077065,
     "user": {
      "displayName": "hardik makkar",
      "userId": "11652027753526196874"
     },
     "user_tz": -330
    },
    "id": "IjNN9jIF0cs6",
    "outputId": "f6a963df-529f-46f4-b819-3c491971f005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Evaluating Student Model on Validation Set...\n",
      "\n",
      "ðŸŽ“ Student Accuracy on Validation Set: 86.85%\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5. ðŸŽ¯ Evaluate Student\n",
    "# -----------------------------\n",
    "print(\"\\nâœ… Evaluating Student Model on Validation Set...\")\n",
    "acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "for x_batch, y_batch in ds_val:\n",
    "    preds = student_model(x_batch, training=False)\n",
    "    acc_metric.update_state(y_batch, preds)\n",
    "\n",
    "final_acc = acc_metric.result().numpy()\n",
    "print(f\"\\nðŸŽ“ Student Accuracy on Validation Set: {final_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41016,
     "status": "ok",
     "timestamp": 1744847167178,
     "user": {
      "displayName": "hardik makkar",
      "userId": "11652027753526196874"
     },
     "user_tz": -330
    },
    "id": "pOzZYPnS_hqN",
    "outputId": "abd42a4f-23f1-475f-e191-9eddfd477eba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Evaluating Student Model on Validation Set...\n",
      "\n",
      "ðŸŽ“ Student Accuracy on Validation Set: 83.69%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nâœ… Evaluating Teacher Model on Validation Set...\")\n",
    "acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "for x_batch, y_batch in ds_val:\n",
    "    preds = teacher_model(x_batch, training=False)\n",
    "    acc_metric.update_state(y_batch, preds)\n",
    "\n",
    "final_acc = acc_metric.result().numpy()\n",
    "print(f\"\\nðŸŽ“ Teacher Accuracy on Validation Set: {final_acc * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNBJDJ0NdzFxp35hQRFN9nK",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
